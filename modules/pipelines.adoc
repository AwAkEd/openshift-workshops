## Lab: Automating Deployment with CI/CD Pipeline

### Background: CI/CD Pipeline
Continuous Integration and Continuous Deployment refer to a set of practises with
the intention of automating various aspects of delivery software. One of these
practises is Pipeline which is an automated process to define the steps a change
in code or configuration has to go through in order to reach upper environments
such as staging and production. OpenShift supports CI/CD Pipelines by integrating
the popular https://jenkins.io/doc/book/pipeline/overview/[Jenkins pipelines] into
the platform and enables defining truly complex workflows directly within OpenShift.

In a previous lab, you deployed the `nationalparks` application using the
https://docs.openshift.com/container-platform/3.3/architecture/core_concepts/builds_and_image_streams.html#source-build[Source-to-Image (S2I)]
mechanism. S2I already provides build automation by automatically running builds
when source code changes, or an underlying image changes. Deployments are also automated
by S2I and can be triggered when the image they are based on changes. In this lab,
you will create a more complex workflow by creating a pipeline that extends the S2I
functionality by adding more steps to the build and deploy process. The following
diagram shows the pipeline you will create in this lab.

image::/images/pipeline-diagram.png[CI/CD Pipeline Diagram,800,align="center"]

There are two environments for the `nationalparks` application in this pipeline.
*Dev* container is the for development and test purposes where all code and
configuration changes are deployed so that you can run automated tests against it.
Furthermore, the test teams can run their manual tests on this container and
report any bugs discovered through their test cases. If the tests are all successful
and the _Deployment Manager_ in the team approves the change, it is then deployed to the
*Live* container which is the production environment with defined SLA and is
critical to function properly at all times.

The pipeline execution starts with a developer making a change in the application
code or configuration. For every change, the following steps are executed with the
goal of determining if the change is appropriate for deployment in the *Live*
environment:

. Clone the code from Git repo, build and run unit tests and build a docker image container the code (S2I)
. Deploy the docker image into *Dev* container
. Run automated tests against the *Dev* container
. Run manual tests against the *Dev* container
. Wait for the *Deployment Manager*'s to either approve or reject the deployment (e.g. manual tests have revealed an unacceptable number of bugs)
. If approved, deployed to the _Live_ container

Let's move on to deploy `Jenkins` and create this pipeline on OpenShift.

### Exercise: Deploy Jenkins

OpenShift provides a certified Jenkins which includes a rich set of plugins that
enable the full pipeline flow. In the web console, create a new project named
`cicd{{USER_SUFFIX}}`.

image::/images/pipeline-project.png[CI/CD Project]

In the `cicd{{USER_SUFFIX}}` project, click on the
*"Add to project"* button, find the `jenkins-ephemeral` template, and click on it.

image::/images/pipeline-jenkins-catalog.png[Jenkins Ephemeral]

You can customize the Jenkins properties such as service name, admin password, memory
allocation, etc through the parameters in the web console. Specify _openshift3_ for
*Jenkins Password* and leave the rest of parameters with the default values. Click on
*Create* to deploy Jenkins.

image::/images/pipeline-jenkins-params.png[Jenkins Template]

OpenShift deploys a Jenkins pod and also creates a service and route for for the
deployed container.

image::/images/pipeline-jenkins-pods.png[Jenkins Pods]

Click on Jenkins route in order to open Jenkins Console. Login in Jenkins using the
admin credentials and explore the Jenkins Console.

NOTE: The admin credentials for Jenkins are: admin/openshift3

image::/images/pipeline-jenkins-console.png[Jenkins Console]

Jenkins uses the OpenShift REST API in order to integrate into various OpenShift
operations and therefore you should grant permission to the Jenkins service account
to invoke these APIs. Run the following CLI command to allow Jenkins to retrieve
information and invoke action in OpenShift.

[source]
----
oc policy add-role-to-user edit system:serviceaccount:cicd{{USER_SUFFIX}}:jenkins -n explore{{USER_SUFFIX}}
----

### Exercise: Create Live Environment

Before creating the pipeline, you need to create a *Live* container that runs the
live version of `nationalparks` application. The `parksmap` front-end will use
the *Live* container for retrieving the geo data so that developers can make frequent
changes in the *Dev* container without interfering with the live application.

First you need to create a new MongoDB container for the *Live* environment. In the
web console in your `explore{{USER_SUFFIX}}` project,  click the *"Add to
Project"* button, and then find the `mongodb-ephemeral` template, and click it.
Use the following values in their respective fields:

* Database Service Name : `mongodb-live`
* MongoDB Connection Username : `mongodb`
* MongoDB Connection Password : `mongodb`
* MongoDB Database Name: `mongodb`
* MongoB Admin Password : `mongodb`

You can leave the rest of the values as their defaults, and then click
*"Create"*. Then click *Continue to overview*. The MongoDB instance should
quickly be deployed.

Now you can create the *Live* container based on the same `nationalparks` docker image
created in link:java[previous labs]. Click on *Builds* &rarr; *Image* and then `nationalparks` to
inspect the docker images created.

image::/images/pipeline-live-image.png[National Parks Image Stream]

Every new https://docs.openshift.com/container-platform/3.3/architecture/core_concepts/builds_and_image_streams.html[S2I build]
results in a new docker image which is identified with the `latest` tag. The *Dev*
and *Live* environments should allow deploying different versions of the `nationalparks`
application so that developers can keep deploying into the *Dev* environment without
affecting the *Live* environments. In order to achieve that, create a new tag
using the following CLI command to reference the docker image that should be deployed
into the *Live* environment:

[source]
----
oc tag nationalparks:latest nationalparks:live
----

When a new S2I build is triggered, a new docker image gets created and the `latest`
tag will automatically refer to the newly built docker image. However the `live` tag
keeps referring to the pervious docker image and therefore leaves the *Live* environment
intact.

After creating the tag, you are ready to deploy the *Live* `nationalparks`
container based on the `nationalparks:live` image. In the web console in your
`explore{{USER_SUFFIX}}` project,  click the *"Add to Project"* button, and
then *Deploy Image* tab. Choose *Image Stream Tag* radio button and refer to the
image tag you just created by giving the following values in each respective field:

* Namespace: `explore{{USER_SUFFIX}}`
* ImageStream: `nationalparks`
* Tag: `live`
* Name: `nationalparks-live`

{% if modules.configmap %}

image::/images/pipeline-live-deploy-config.png[National Parks Live Deploy]

{% else %}

Specify the following environment variable to wire the *Live* container to the
*Live* database:

* `MONGODB_SERVER_HOST`: `mongodb-live`
* `MONGODB_USER`: `mongodb`
* `MONGODB_PASSWORD`: `mongodb`
* `MONGODB_DATABASE`: `mongodb`

image::/images/pipeline-live-deploy-env.png[National Parks Live Deploy]

{% endif %}

You can leave the rest of the values as their defaults, and then click
*"Create"*. Then click *Continue to overview*.

{% if modules.configmap %}

The database configuration was created through the use of `ConfigMaps` in the link:configmap[previous
labs]. Download the properties file to your local machine and create a new `ConfigMap`
to configure the *Live* environment: +
https://raw.githubusercontent.com/openshift-roadshow/nationalparks/{{NATIONALPARKS_VERSION}}/ose3/application-live.properties

[source]
----
oc create configmap nationalparks-live --from-file=application.properties=lab/application-live.properties
oc set volumes dc/nationalparks --add -m /config --configmap-name=nationalparks-live
----

{% endif %}

Group the *Live* services
by clicking on the *Group Service* on the right side of *NATIONALPARKS LIVE*
container and choosing `mongodb-live` from the drop-down list.

image::/images/pipeline-live.png[National Parks Live]

If you look at the web console, you will notice that, when you create the
application this way, OpenShift doesn't create a *Route* for you. Click on
*Create Route* on the top right corner of *NATIONALPARKS LIVE* container and
then *Create* to create a route with the default values.

Similar to the link:databases[previous labs], populate the database by pointing your browser to the
`nationalparks-live` route url:

[source]
----
http://nationalparks-live-explore{{USER_SUFFIX}}.{{ROUTER_ADDRESS}}/ws/data/load/
----

As discussed in link:databases[previous labs], the `parksmap` web app queries the OpenShift API and
looks for services that have the label `type=parksmap-backend` and interrogates the
discovered endpoints to visualize their map data. After creating the pipeline,
`parksmap` should use the *Live* container instead of the *Dev* container so that
deployments to the *Dev* container does not disrupt the `parksmap` application.
You can do that by removing the `type` label from the *Dev* service and adding it
to the *Live* service:

[source]
----
oc label svc nationalparks type-
oc label service nationalparks-live type=parksmap-backend
----

### Exercise: Create OpenShift Pipeline

The Pipeline is in fact a type of build that allows developers to define a Jenkins
pipeline for execution by the Jenkins pipeline plugin. The build can be started,
monitored, and managed by OpenShift Container Platform in the same way as any other
build type. Pipeline workflows are defined in a Jenkinsfile, either embedded directly
in the build configuration, or supplied in a Git repository and referenced by the
build configuration.

In order to create the pipeline, import the pipeline template created for this lab.

[source]
----
oc project cicd{{USER_SUFFIX}}
oc create -f https://raw.githubusercontent.com/openshift-roadshow/nationalparks/{{NATIONALPARKS_VERSION}}/ose3/pipeline-template.yaml
----

In the `cicd{{USER_SUFFIX}}` project, click on the *"Add to project"* button,
find the `dev-live-pipeline` template, and click on it. Specify the project name
and click on *Create*

NOTE: Specify the name of the project (e.g.`explore{{USER_SUFFIX}}`) where
`nationalparks` *Dev* and *Live* containers are deployed.

image::/images/pipeline-template.png[Pipeline Template]

In order to trigger the pipeline, Go to *Builds* &rarr; *Pipelines* on the left
side-bar and click on *Start Pipeline* to start the exection of `nationalparks-pipeline`.
You can click on *View Log* to take a look at the build logs as they progress
through the pipeline or on *Build #N* to see the details of this specific pipeline
execution as well as the pipeline definition using the https://jenkins.io/doc/book/pipeline/overview/[Jenkins DSL].

image::/images/pipeline-details.png[Pipeline Details]

When the pipeline reaches the *Deploy Dev* stage, a new deployment takes place to the *Dev* container
while leaving the *Live* container intact, not to disrupt the live environment.

NOTE: You will notice there are no containers in the *Live* environment. That is
because this is the first run of the pipeline and no deployments have taken place
yet so far in the pipeline in the *Live* container.

image::/images/pipeline-deploy-dev.png[Pipeline - Deploy to Dev]

Pipeline execution will pause after running automated tests against the *Dev*
container. Visit the `nationalparks` web service to query for data and verify the
service works as expected.

[source]
----
http://nationalparks-explore{{USER_SUFFIX}}.{{ROUTER_ADDRESS}}/ws/data/all/
----

After the test stage, pipeline waits for manual approval in order to deploy to the
*Live* container.

image::/images/pipeline-input.png[Manual Approval]

Click on *Input Required* link which takes you to the Jenkins Console for approving
the deployment. This step typically will be integrated into your workflow process
(e.g. JIRA Service Desk and ServiceNow) and will be performed as part of the overall
deployment process without interacting directly with Jenkins. For simplicity in
this lab, click on *Proceed* button to approve the build.

image::/images/pipeline-jenkins-input.png[Jenkins Approval,1000,align=center]

Pipeline execution continues to promote and deploy the `nationalparks` docker image
which was successfully tested in the *Dev* container, to the *Live* container.

On *Builds* &rarr; *Pipelines*, click on *View History* to go to the pipeline overview
which shows the pipeline execution history as well as build time metrics so that you can
iteratively improve the build process as well detect build time anomalies which usually
signal a bad change in the code or configuration.

NOTE: Build metrics are generated and displayed after a few executions of the pipeline
to determine trends.

image::/images/pipeline-history.png[OpenShift History]

Congratulations! Now you have a CI/CD Pipeline for the `nationalparks` application.
